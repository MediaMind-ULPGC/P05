{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 4: Detección de características \n",
    "\n",
    "## Participantes:\n",
    "- Gerardo León Quintana\n",
    "- Susana Suárez Mendoza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformations.transformation_factory import TransformationsFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: \n",
    "\n",
    "Desarrolle una aplicación que permita:\n",
    "\n",
    "a. A través de la interfaz modificar los parámetros del detector de características SIFT.\n",
    "\n",
    "b. Seleccionar un área de interés en una imagen de elección una imagen de naturaleza médica y una imagen telemétrica. \n",
    "\n",
    "c. Buscar esa área de interés (recuádrela en rojo) dentro de diferentes versiones de la imagen de partida (con cambios de traslación, escala y rotación) [NOTA: Estos cambios se pueden acometer con un editor de imágenes o con el trabajo hecho en prácticas previas]. Altere mediante la interfaz las configuraciones de parámetros para mejorar la detección. \n",
    "\n",
    "d. Pruebe a hacer lo mismo que en el apartado c. con diferentes grados de deformación de la imagen. [NOTA: Estos cambios se pueden acometer con un editor de imágenes o con el trabajo hecho en prácticas previas].\n",
    "\n",
    "(OPICIONAL)\n",
    "A partir del detector de características “corrija” la imagen alterada para que se alinee con la imagen fuente. \n",
    "\n",
    "NOTA 1: Si no encuentra el área de interés la aplicación debería notificarlo. \n",
    "NOTA 2: Puede preprocesar la imagen con alguna técnica (suavizado, contrastado,…) si lo estima necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img(img):\n",
    "\n",
    "    img1 = TransformationsFactory.initialize_transformation('Traslacion').apply(img)\n",
    "    img2 = TransformationsFactory.initialize_transformation('Rotacion').apply(img)\n",
    "    img3 = TransformationsFactory.initialize_transformation('Escalado').apply(img)\n",
    "\n",
    "    img4, img5 = TransformationsFactory.initialize_transformation('Distorciones').apply(img)\n",
    "    random_choice = random.choice([img1, img2, img3])\n",
    "    img6 = TransformationsFactory.initialize_transformation('Ruido').apply(random_choice)\n",
    "    \n",
    "    return img1, img2, img3, img4, img5, img6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_noise(img):\n",
    "    sted_dev = np.std(img)\n",
    "\n",
    "    if sted_dev > 50:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise(img):\n",
    "\n",
    "    for i in range(10):\n",
    "        img = cv.medianBlur(img, 5)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sift(sift, img_orig):\n",
    "    founded_matches = []\n",
    "\n",
    "    img1, img2, img3, img4, img5, img6 = transform_img(img_orig)\n",
    "    interest_area = cv.imread('interest_area.png', cv.IMREAD_GRAYSCALE)\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(interest_area, None)\n",
    "\n",
    "    for img in [img1, img2, img3,  img4, img5, img6]:\n",
    "        \n",
    "        if has_noise(img):\n",
    "            img = reduce_noise(img)\n",
    "        \n",
    "        try:\n",
    "            keypoints2, descriptors2 = sift.detectAndCompute(img, None)\n",
    "            bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)\n",
    "\n",
    "            matches = bf.match(descriptors1, descriptors2)\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "            best_matches = matches[:10]\n",
    "            img_matches = cv.drawMatches(interest_area, keypoints1, img, keypoints2, best_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "            founded_matches.append(cv.cvtColor(img_matches, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        except:\n",
    "            print(\"Error\")\n",
    "            founded_matches.append(img)\n",
    "    \n",
    "    return founded_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_image(img_orig, nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma):\n",
    "\n",
    "    sift = cv.SIFT_create(nfeatures=nfeatures, nOctaveLayers=nOctaveLayers, contrastThreshold=contrastThreshold, edgeThreshold=edgeThreshold, sigma=sigma)\n",
    "\n",
    "    img1, img2, img3, _, _, _ = transform_img(img_orig)\n",
    "    transformed_img = random.choice([img1, img2, img3])\n",
    "\n",
    "    keyponits1, descriptors1 = sift.detectAndCompute(img_orig, None)\n",
    "    keyponits2, descriptors2 = sift.detectAndCompute(transformed_img, None)\n",
    "\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)\n",
    "\n",
    "    try:\n",
    "        matches = bf.match(descriptors1, descriptors2)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        best_matches = matches[:50]\n",
    "        src_pts = np.float32([keyponits1[m.queryIdx].pt for m in best_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keyponits2[m.trainIdx].pt for m in best_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv.findHomography(dst_pts, src_pts, cv.RANSAC, 5.0)\n",
    "\n",
    "        height, width = img_orig.shape[:2]\n",
    "        size = (width, height)\n",
    "        aligned_img = cv.warpPerspective(transformed_img, M, size)\n",
    "\n",
    "        return aligned_img, transformed_img\n",
    "        \n",
    "    except:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.zeros((1024, 1024, 3), dtype=np.uint8) + 255\n",
    "img = cv.imread('Tumores/tumor_glioma/Tr-gl_0516.jpg')\n",
    "img_orig = img.copy()\n",
    "\n",
    "\n",
    "# Parámetros de SIFT por defecto\n",
    "nfeatures = 500\n",
    "nOctaveLayers = 3\n",
    "contrastThreshold = 0.04\n",
    "edgeThreshold = 10\n",
    "sigma = 1.6\n",
    "\n",
    "coordinates = []\n",
    "drawing = False \n",
    "start_point = None\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def draw_shape(event, x, y, flags, param):\n",
    "    global start_point, drawing, coordinates\n",
    "\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        start_point = (x, y)\n",
    "        \n",
    "\n",
    "    # Dibujar la figura mientras se mueve el mouse\n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            img_copy = img.copy()\n",
    "            cv.rectangle(img_copy, start_point, (x, y), color, thickness)\n",
    "            cv.imshow('image', img_copy)\n",
    "\n",
    "    # Dibujar la figura al soltar el click\n",
    "    elif event == cv.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        end_point = (x, y)\n",
    "        cv.rectangle(img, start_point, end_point, color, thickness)\n",
    "        coordinates.append((start_point, end_point))\n",
    "        cv.imshow('image', img)\n",
    "        extract_interest_area(start_point, end_point, img_orig)\n",
    "\n",
    "\n",
    "def extract_interest_area(start_point, end_point, img):\n",
    "    x1, y1 = start_point\n",
    "    x2, y2 = end_point\n",
    "    if x1 < x2 and y1 < y2:\n",
    "        interest_area = img[y1:y2, x1:x2]\n",
    "    else:\n",
    "        interest_area = img[y2:y1, x2:x1]\n",
    "    cv.imwrite('interest_area.png', interest_area)\n",
    "\n",
    "\n",
    "\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image', draw_shape)\n",
    "cv.createTrackbar('Features', 'image', nfeatures, 800, nothing)\n",
    "cv.createTrackbar('Layers', 'image', nOctaveLayers, 10, nothing)\n",
    "cv.createTrackbar('Contrast', 'image', int(contrastThreshold*100), 100, nothing)\n",
    "cv.createTrackbar('Edge', 'image', edgeThreshold, 100, nothing)\n",
    "cv.createTrackbar('Sigma', 'image', int(sigma*10), 100, nothing)\n",
    "\n",
    "cv.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "\n",
    "    nfeatures = cv.getTrackbarPos('Features', 'image')\n",
    "    nOctaveLayers = cv.getTrackbarPos('Layers', 'image')\n",
    "    contrastThreshold = cv.getTrackbarPos('Contrast', 'image') / 100\n",
    "    edgeThreshold = cv.getTrackbarPos('Edge', 'image')\n",
    "    sigma = cv.getTrackbarPos('Sigma', 'image') / 10\n",
    "    \n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "    elif key == ord('r'):\n",
    "        img = img_orig.copy()\n",
    "        coordinates = []\n",
    "        os.remove('interest_area.png')\n",
    "\n",
    "        cv.imshow('image', img)\n",
    "    \n",
    "    elif key == ord('d'):\n",
    "        sift = cv.SIFT_create(nfeatures=nfeatures, nOctaveLayers=nOctaveLayers, contrastThreshold=contrastThreshold, edgeThreshold=edgeThreshold, sigma=sigma)\n",
    "        if os.path.exists('interest_area.png'):\n",
    "            founded_matches = apply_sift(sift, img_orig)\n",
    "            cv.imshow('Traslacion', founded_matches[0])\n",
    "            cv.imshow('Rotacion', founded_matches[1])\n",
    "            cv.imshow('Escala', founded_matches[2])\n",
    "            cv.imshow('Barril', founded_matches[3])\n",
    "            cv.imshow('Cojin', founded_matches[4])\n",
    "            cv.imshow('Ruido', founded_matches[5])\n",
    "        else:\n",
    "            print('No se ha seleccionado un área de interés')\n",
    "            # TODO: mensaje por ventana P2\n",
    "    \n",
    "    elif key == ord('a'):\n",
    "        aligned_img, img_transformed = align_image(img_orig , nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma)\n",
    "        if aligned_img is not None and img_transformed is not None:\n",
    "            cv.imshow('Transformed Image', img_transformed)\n",
    "            cv.imshow('Aligned Image', aligned_img)\n",
    "        else:\n",
    "            #TODO: mensaje por ventana P2\n",
    "            print('No se han encontrado coincidencias')\n",
    "\n",
    "    elif key == 8:\n",
    "\n",
    "        try:\n",
    "            cv.destroyWindow('Traslacion')\n",
    "            cv.destroyWindow('Rotacion')\n",
    "            cv.destroyWindow('Escala')\n",
    "            cv.destroyWindow('Barril')\n",
    "            cv.destroyWindow('Cojin')\n",
    "            cv.destroyWindow('Ruido')\n",
    "            \n",
    "            img = img_orig.copy()\n",
    "            coordinates = []\n",
    "            os.remove('interest_area.png')\n",
    "\n",
    "            cv.imshow('image', img)\n",
    "        except:\n",
    "            cv.destroyWindow('Transformed Image')\n",
    "            cv.destroyWindow('Aligned Image')\n",
    "            \n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: OPCIONAL -> enseñar a JC Reyes\n",
    "\n",
    "# TODO: NOTIFICACIÓNES\n",
    "\n",
    "# TODO: UN EJEMPLO DE USAVIZAD\n",
    "\n",
    "# TODO: EJEMPLO NOTEBOOK BONITO\n",
    "\n",
    "# TODO: OPCIONAL: EJEMPLO DEL TIMOR EN OTRAS CARPETAS- opcional tkintwe\n",
    "# TODO: MANUAL\n",
    "\n",
    "# TODO: README\n",
    "# TODO: PREGUNTAR DIA DE DEFENSAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
